{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TFwaJir_Olj"
      },
      "source": [
        "# ML2025 Homework 1 - Retrieval Augmented Generation with Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tQHdH2k_Olk"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will mount your own Google Drive and change the working directory."
      ],
      "metadata": {
        "id": "-_ZkNxqGGhdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DWQh-lq8GuwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c6f47f-c63f-45f4-d1f9-90991f72ae37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the working directory to somewhere in your Google Drive.\n",
        "# You could check the path by right clicking on the folder.\n",
        "# %cd [change to the directory you prefer]\n",
        "%cd /content/drive/MyDrive/QA"
      ],
      "metadata": {
        "id": "P_5Tf1rMHBQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fb2334-6a52-467d-ee3c-b692c3624ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/QA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGx000oZ_Oll"
      },
      "source": [
        "In this section, we install the necessary python packages and download model weights of the quantized version of LLaMA 3.1 8B. Also, download the dataset. Note that the model weight is around 8GB. If you are using your Google Drive as the working directory, make sure you have enough space for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JywoPOO_Oll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93a5c77-e3a1-4429-e8dc-702cab9bfea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
            "Collecting llama-cpp-python==0.3.4\n",
            "  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu122/llama_cpp_python-0.3.4-cp311-cp311-linux_x86_64.whl (445.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.2/445.2 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.3.4)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.3.4) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.4\n",
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (4.13.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (2.32.3)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from lxml_html_clean) (5.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.14.1)\n",
            "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.7.14)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.7.0)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.23.0)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\n",
            "Downloading w3lib-2.3.1-py3-none-any.whl (21 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: parse, appdirs, websockets, w3lib, urllib3, pyee, lxml_html_clean, fake-useragent, cssselect, pyquery, pyppeteer, bs4, requests-html, googlesearch-python\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.2 requires websockets>=14.0, but you have websockets 10.4 which is incompatible.\n",
            "google-genai 1.25.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 10.4 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.3.0 fake-useragent-2.2.0 googlesearch-python-1.3.0 lxml_html_clean-0.4.2 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.3.1 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install --no-cache-dir llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "!python3 -m pip install googlesearch-python bs4 charset-normalizer requests-html lxml_html_clean\n",
        "\n",
        "from pathlib import Path\n",
        "if not Path('./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf').exists():\n",
        "    !wget https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\n",
        "if not Path('./public.txt').exists():\n",
        "    !wget https://www.csie.ntu.edu.tw/~ulin/public.txt\n",
        "if not Path('./private.txt').exists():\n",
        "    !wget https://www.csie.ntu.edu.tw/~ulin/private.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX6SizAt_Olm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acacafc-177a-4678-fd28-ba7a8577cf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are good to go!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    raise Exception('You are not using the GPU runtime. Change it first or you will suffer from the super slow inference speed!')\n",
        "else:\n",
        "    print('You are good to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iyc1qC_Olm"
      },
      "source": [
        "## Prepare the LLM and LLM utility function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T59vxAo2_Olm"
      },
      "source": [
        "By default, we will use the quantized version of LLaMA 3.1 8B. you can get full marks on this homework by using the provided LLM and LLM utility function. You can also try out different LLM models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtepTeT3_Olm"
      },
      "source": [
        "In the following code block, we will load the downloaded LLM model weights onto the GPU first.\n",
        "Then, we implemented the generate_response() function so that you can get the generated response from the LLM model more easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVil2Vhe_Olm"
      },
      "source": [
        "You can ignore \"llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\" warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScyW45N__Olm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad815639-4a2f-45d5-c1ce-f504f4e769ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load the model onto GPU\n",
        "llama3 = Llama(\n",
        "    \"./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\",\n",
        "    verbose=False,\n",
        "    n_gpu_layers=-1,\n",
        "    n_ctx=16384,    # This argument is how many tokens the model can take. The longer the better, but it will consume more memory. 16384 is a proper value for a GPU with 16GB VRAM.\n",
        ")\n",
        "\n",
        "def generate_response(_model: Llama, _messages: str) -> str:\n",
        "    '''\n",
        "    This function will inference the model with given messages.\n",
        "    '''\n",
        "    _output = _model.create_chat_completion(\n",
        "        _messages,\n",
        "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
        "        max_tokens=512,    # This argument is how many tokens the model can generate, you can change it and observe the differences.\n",
        "        temperature=0,      # This argument is the randomness of the model. 0 means no randomness. You will get the same result with the same input every time. You can try to set it to different values.\n",
        "        repeat_penalty=2.0,\n",
        "    )[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return _output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHLwq-4_Olm"
      },
      "source": [
        "## Search Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYM-2ZsE_Olm"
      },
      "source": [
        "The TA has implemented a search tool for you to search certain keywords using Google Search. You can use this tool to search for the relevant **web pages** for the given question. The search tool can be integrated in the following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEIRmZl7_Oln"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from googlesearch import search as _search\n",
        "from bs4 import BeautifulSoup\n",
        "from charset_normalizer import detect\n",
        "import asyncio\n",
        "from requests_html import AsyncHTMLSession\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "\n",
        "async def worker(s:AsyncHTMLSession, url:str):\n",
        "    try:\n",
        "        header_response = await asyncio.wait_for(s.head(url, verify=False), timeout=10)\n",
        "        if 'text/html' not in header_response.headers.get('Content-Type', ''):\n",
        "            return None\n",
        "        r = await asyncio.wait_for(s.get(url, verify=False), timeout=10)\n",
        "        return r.text\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "async def get_htmls(urls):\n",
        "    session = AsyncHTMLSession()\n",
        "    tasks = (worker(session, url) for url in urls)\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "async def search(keyword: str, n_results: int=3) -> List[str]:\n",
        "    '''\n",
        "    This function will search the keyword and return the text content in the first n_results web pages.\n",
        "\n",
        "    Warning: You may suffer from HTTP 429 errors if you search too many times in a period of time. This is unavoidable and you should take your own risk if you want to try search more results at once.\n",
        "    The rate limit is not explicitly announced by Google, hence there's not much we can do except for changing the IP or wait until Google unban you (we don't know how long the penalty will last either).\n",
        "    '''\n",
        "    keyword = keyword[:100]\n",
        "    # First, search the keyword and get the results. Also, get 2 times more results in case some of them are invalid.\n",
        "    results = list(_search(keyword, n_results * 2, lang=\"zh\", unique=True))\n",
        "    # Then, get the HTML from the results. Also, the helper function will filter out the non-HTML urls.\n",
        "    results = await get_htmls(results)\n",
        "    # Filter out the None values.\n",
        "    results = [x for x in results if x is not None]\n",
        "    # Parse the HTML.\n",
        "    results = [BeautifulSoup(x, 'html.parser') for x in results]\n",
        "    # Get the text from the HTML and remove the spaces. Also, filter out the non-utf-8 encoding.\n",
        "    results = [''.join(x.get_text().split()) for x in results if detect(x.encode()).get('encoding') == 'utf-8']\n",
        "    # Return the first n results.\n",
        "    return results[:n_results]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC3zQjjj_Oln"
      },
      "source": [
        "## Test the LLM inference pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dmGCARd_Oln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9489f50-ec45-402f-e315-b79a16ca270b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "泰勒絲（Taylor Swift）是一位美國歌手、詞曲作家和音樂製作人。她出生於1989年，來自田納西州。她的音乐风格从乡村摇滚发展到流行搖擺，並且她被誉为当代最成功的女艺人的之一。\n",
            "\n",
            "泰勒絲早期在鄉郊小鎮演唱會時開始發展音樂事業，她推出了多張專輯，包括《Taylor Swift》、《Fearless》，以及後來更為知名的大熱作如 《1989》（2014年）、_reputation（）和 _Lover （）。她的歌曲經常探討愛情、友誼及自我成長等主題。\n",
            "\n",
            "泰勒絲獲得了許多獎項，包括13座格萊美奖，並且是史上最快達到百萬銷量的女藝人之一。\n"
          ]
        }
      ],
      "source": [
        "# You can try out different questions here.\n",
        "test_question='請問誰是 Taylor Swift？'\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"你是 LLaMA-3.1-8B，是用來回答問題的 AI。使用中文時只會使用繁體中文來回問題。\"},    # System prompt\n",
        "    {\"role\": \"user\", \"content\": test_question}, # User prompt\n",
        "]\n",
        "\n",
        "print(generate_response(llama3, messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0-ojJuE_Oln"
      },
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGsIPud3_Oln"
      },
      "source": [
        "The TA has implemented the Agent class for you. You can use this class to create agents that can interact with the LLM model. The Agent class has the following attributes and methods:\n",
        "- Attributes:\n",
        "    - role_description: The role of the agent. For example, if you want this agent to be a history expert, you can set the role_description to \"You are a history expert. You will only answer questions based on what really happened in the past. Do not generate any answer if you don't have reliable sources.\".\n",
        "    - task_description: The task of the agent. For example, if you want this agent to answer questions only in yes/no, you can set the task_description to \"Please answer the following question in yes/no. Explanations are not needed.\"\n",
        "    - llm: Just an indicator of the LLM model used by the agent.\n",
        "- Method:\n",
        "    - inference: This method takes a message as input and returns the generated response from the LLM model. The message will first be formatted into proper input for the LLM model. (This is where you can set some global instructions like \"Please speak in a polite manner\" or \"Please provide a detailed explanation\".) The generated response will be returned as the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjG-UwDX_Oln"
      },
      "outputs": [],
      "source": [
        "class LLMAgent():\n",
        "    def __init__(self, role_description: str, task_description: str, llm:str=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\"):\n",
        "        self.role_description = role_description   # Role means who this agent should act like. e.g. the history expert, the manager......\n",
        "        self.task_description = task_description    # Task description instructs what task should this agent solve.\n",
        "        self.llm = llm  # LLM indicates which LLM backend this agent is using.\n",
        "    def inference(self, message:str) -> str:\n",
        "        if self.llm == 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF': # If using the default one.\n",
        "            # TODO: Design the system prompt and user prompt here.\n",
        "            # Format the messsages first.\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": f\"{self.role_description}\"},  # Hint: you may want the agents to speak Traditional Chinese only.\n",
        "                {\"role\": \"user\", \"content\": f\"{self.task_description}\\n{message}\"}, # Hint: you may want the agents to clearly distinguish the task descriptions and the user messages. A proper seperation text rather than a simple line break is recommended.\n",
        "            ]\n",
        "            return generate_response(llama3, messages)\n",
        "        else:\n",
        "            # TODO: If you want to use LLMs other than the given one, please implement the inference part on your own.\n",
        "            return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ueJrgP_Oln"
      },
      "source": [
        "TODO: Design the role description and task description for each agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzPzmNnj_Oln"
      },
      "outputs": [],
      "source": [
        "# TODO: Design the role and task description for each agent.\n",
        "\n",
        "# This agent may help you filter out the irrelevant parts in question descriptions.\n",
        "question_extraction_agent = LLMAgent(\n",
        "    role_description=\"\",\n",
        "    task_description=\"\",\n",
        ")\n",
        "\n",
        "# This agent may help you extract the keywords in a question so that the search tool can find more accurate results.\n",
        "keyword_extraction_agent = LLMAgent(\n",
        "    role_description=\"\",\n",
        "    task_description=\"\",\n",
        ")\n",
        "\n",
        "# This agent is the core component that answers the question.\n",
        "qa_agent = LLMAgent(\n",
        "    role_description=\"你是 LLaMA-3.1-8B，是用來回答問題的 AI。使用中文時只會使用繁體中文來回問題。\",\n",
        "    task_description=\"請回答以下問題：\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9eoywr7_Oln"
      },
      "source": [
        "## RAG pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HDOjNYJ_Oln"
      },
      "source": [
        "TODO: Implement the RAG pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRGNa-1i_Oln"
      },
      "source": [
        "Please refer to the homework description slides for hints.\n",
        "\n",
        "Also, there might be more heuristics (e.g. classifying the questions based on their lengths, determining if the question need a search or not, reconfirm the answer before returning it to the user......) that are not shown in the flow charts. You can use your creativity to come up with a better solution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMaIsKAZ_Olo"
      },
      "source": [
        "- Naive approach (simple baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/naive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mppO-oOO_Olo"
      },
      "source": [
        "- Naive RAG approach (medium baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/naive_rag.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYxbciLO_Olo"
      },
      "source": [
        "- RAG with agents (strong baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/rag_agent.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztJkA7R7_Olo"
      },
      "outputs": [],
      "source": [
        "async def pipeline(question: str) -> str:\n",
        "    # TODO: Implement your pipeline.\n",
        "    # Currently, it only feeds the question directly to the LLM.\n",
        "    # You may want to get the final results through multiple inferences.\n",
        "    # Just a quick reminder, make sure your input length is within the limit of the model context window (16384 tokens), you may want to truncate some excessive texts.\n",
        "    return qa_agent.inference(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer the questions using your pipeline!"
      ],
      "metadata": {
        "id": "P_kI_9EGB0S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Colab has usage limit, you might encounter the disconnections. The following code will save your answer for each question. If you have mounted your Google Drive as instructed, you can just rerun the whole notebook to continue your process."
      ],
      "metadata": {
        "id": "PN17sSZ8DUg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./qa.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "F6DPPkYQsgXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "R68A9FrqttGj",
        "outputId": "d7e68850-718c-4ee7-9691-942dba5bd1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  问题  \\\n",
              "0  校歌為學校（包括小學、中學、大學等）宣告或者規定的代表該校的歌曲。用於體現該校的治學理念、辦...   \n",
              "1  2025年初，NCC透過行政命令，規定民眾如果透過境外郵購無線鍵盤、滑鼠、藍芽耳機..等自用...   \n",
              "2                          第一代 iPhone 是由哪位蘋果 CEO 發表？   \n",
              "3       台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 要達到多少分才能申請？   \n",
              "4                          Rugby Union 中觸地 try 可得幾分？   \n",
              "\n",
              "                                         答案  \n",
              "0                   「虎山雄風飛揚」是「光華國小」學校的校歌歌詞。  \n",
              "1                            每案一律加收審查費750元。  \n",
              "2        第一代 iPhone 是由Steve Jobs（史提夫賈伯斯）發表。  \n",
              "3  台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 72分才能申請  \n",
              "4                  Rugby Union 中觸地 try 可得5分  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4ed26d1-1360-40db-803b-2418eec4c8e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>问题</th>\n",
              "      <th>答案</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>校歌為學校（包括小學、中學、大學等）宣告或者規定的代表該校的歌曲。用於體現該校的治學理念、辦...</td>\n",
              "      <td>「虎山雄風飛揚」是「光華國小」學校的校歌歌詞。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025年初，NCC透過行政命令，規定民眾如果透過境外郵購無線鍵盤、滑鼠、藍芽耳機..等自用...</td>\n",
              "      <td>每案一律加收審查費750元。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>第一代 iPhone 是由哪位蘋果 CEO 發表？</td>\n",
              "      <td>第一代 iPhone 是由Steve Jobs（史提夫賈伯斯）發表。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 要達到多少分才能申請？</td>\n",
              "      <td>台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 72分才能申請</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rugby Union 中觸地 try 可得幾分？</td>\n",
              "      <td>Rugby Union 中觸地 try 可得5分</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4ed26d1-1360-40db-803b-2418eec4c8e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4ed26d1-1360-40db-803b-2418eec4c8e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4ed26d1-1360-40db-803b-2418eec4c8e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d2fb59bd-d7e8-4a5e-a778-853649e6cd11\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2fb59bd-d7e8-4a5e-a778-853649e6cd11')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d2fb59bd-d7e8-4a5e-a778-853649e6cd11 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"\\u95ee\\u9898\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"\\u300a\\u6975\\u9650\\u9ad4\\u80fd\\u738bSASUKE\\u300b\\u662f\\u65e5\\u672cTBS\\u96fb\\u8996\\u53f0\\u4e0d\\u5b9a\\u671f\\u64ad\\u51fa\\u7684\\u904b\\u52d5\\u5a1b\\u6a02\\u7279\\u5225\\u7bc0\\u76ee\\uff0c\\u5176\\u8eab\\u53d7\\u65e5\\u672c\\u89c0\\u773e\\u559c\\u611b\\uff0c\\u5728\\u65e5\\u672c\\u64c1\\u6709\\u9ad8\\u6536\\u8996\\u7387\\u3002\\u300a\\u6975\\u9650\\u9ad4\\u80fd\\u738bSASUKE\\u300b\\u5728\\u5168\\u4e16\\u754c\\u6709\\u4e0d\\u5c0f\\u7684\\u77e5\\u540d\\u5ea6\\uff0c\\u4e26\\u4e0d\\u50c5\\u50c5\\u662f\\u5728\\u4e0d\\u540c\\u570b\\u5bb6\\u64ad\\u51fa\\u7bc0\\u76ee\\uff0c\\u751a\\u81f3\\u572818\\u500b\\u570b\\u5bb6\\u6216\\u5730\\u5340\\u9084\\u8207\\u7576\\u5730\\u96fb\\u8996\\u53f0\\u5408\\u4f5c\\u88fd\\u4f5c\\u5728\\u5730\\u7248\\u7684\\u300a\\u6975\\u9650\\u9ad4\\u80fd\\u738bSASUKE\\u300b\\u7bc0\\u76ee\\u3002\\u8acb\\u554f2024\\u5e74\\u7684\\u7b2c42\\u56de\\u300a\\u6975\\u9650\\u9ad4\\u80fd\\u738bSASUKE\\u300b\\u57282024\\u5e74\\u7684\\u54ea\\u4e00\\u5929\\u9996\\u64ad\\uff1f\",\n          \"\\u300c\\u5982\\u679c\\u4f60\\u670b\\u53cb\\u5531\\u6b4c\\u6c92\\u6709\\u8dd1\\u8abf\\uff0c\\u4e00\\u5b9a\\u662f\\u4ed6\\u7684\\u4f34\\u4fb6\\u8dd1\\u6389\\u4e86\\u300d\\u662f\\u4e00\\u53e5\\u7528\\u4f86\\u5f62\\u5bb9\\u5931\\u6200\\u4e4b\\u4eba\\u5531\\u6b4c\\u6a21\\u6a23\\u7684\\u7db2\\u8def\\u7b11\\u8a71\\u3002\\u300c\\u77ed\\u66ab\\u4ea4\\u6703\\u7684\\u65c5\\u7a0b\\u5c31\\u6b64\\u5206\\u5c94\\u300d\\u662f\\u54ea\\u500b\\u6b4c\\u5531\\u5718\\u9ad4\\u6b4c\\u66f2\\u4e2d\\u7684\\u6b4c\\u8a5e\\uff1f\",\n          \"\\u76f8\\u50b3\\u5728\\u53f0\\u7063\\u5927\\u5b78\\u7684\\u67d0\\u4e00\\u5802\\u7a0b\\u5f0f\\u8a2d\\u8a08\\u8ab2\\u7a0b\\u5f9e\\u4f86\\u4e0d\\u6703\\u9032\\u884c\\u5206\\u7d44\\uff0c\\u5982\\u679c\\u6709\\u4eba\\u554f\\u70ba\\u751a\\u9ebc\\u6c92\\u6709\\u5206\\u7d44\\uff0c\\u8001\\u5e2b\\u7e3d\\u6703\\u8aaa\\u300c\\u6211\\u4e0a\\u8ab2\\u90fd\\u4e0d\\u5206\\u7d44\\u7684\\u3002\\u5206\\u7d44\\u7684\\u7d50\\u679c\\u901a\\u5e38\\u90fd\\u662f\\u4e00\\u500b\\u963f\\u5b85\\u5728\\u5bebcode\\uff1b\\u4e00\\u500b\\u672a\\u4f86\\u53ef\\u4ee5\\u7576PM\\u7684\\u5728\\u53f0\\u4e0a\\u5439\\u725b\\uff1b\\u4e00\\u500b\\u5ee2\\u67f4\\u8dd1\\u53bb\\u8cb7\\u4fbf\\u7576\\u300d\\u3002\\u8acb\\u554f\\u8b1b\\u51fa\\u9019\\u53e5\\u8a71\\u7684\\u8001\\u5e2b\\u662f\\u8ab0\\uff1f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u7b54\\u6848\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"2024\\u5e7412\\u670825\\u65e5\\u64ad\\u51fa\",\n          \"\\u300c\\u77ed\\u66ab\\u4ea4\\u6703\\u7684\\u65c5\\u7a0b\\u5c31\\u6b64\\u5206\\u5c94\\u300d\\u662f\\u300c\\u52d5\\u529b\\u706b\\u8eca\\u300d\\u6b4c\\u66f2\\u4e2d\\u7684\\u6b4c\\u8a5e\\u3002\",\n          \"\\u5289\\u90a6\\u92d2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "PREFIX = \"test\"\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    question = row['问题']\n",
        "    # answer   = row['答案']\n",
        "    # print(f\"{idx + 1} | 问题: {question} | 答案: {answer}\")\n",
        "    if Path(f\"./{PREFIX}_{idx + 1}.txt\").exists():\n",
        "            continue\n",
        "    answer = await pipeline(question)\n",
        "    answer = answer.replace('\\n',' ')\n",
        "    print(idx + 1, answer)\n",
        "    with open(f'./{PREFIX}_{idx + 1}.txt', 'w') as output_f:\n",
        "        print(answer, file=output_f)"
      ],
      "metadata": {
        "id": "NKBz0JRYuXBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the results into one file.\n",
        "with open(f'./{PREFIX}.txt', 'w') as output_f:\n",
        "    for id in range(1,91):\n",
        "        with open(f'./{PREFIX}_{id}.txt', 'r') as input_f:\n",
        "            answer = input_f.readline().strip()\n",
        "            print(answer, file=output_f)"
      ],
      "metadata": {
        "id": "HLbcE7E27zeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Using gemini api to evaluate the correctness of answers."
      ],
      "metadata": {
        "id": "1oD7XgWT8Kgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check model list\n",
        "models = genai.list_models()\n",
        "for m in models:\n",
        "    print(m.name, m.supported_generation_methods)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hbd3-nWdCO6Y",
        "outputId": "04646685-0bac-4f56-f103-7a623cf460c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001 ['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro-vision-latest ['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-2.5-pro-preview-03-25 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-05-20 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite-preview-06-17 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-05-06 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-06-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp-02-05 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-tts ['countTokens', 'generateContent']\n",
            "models/gemini-2.5-pro-preview-tts ['countTokens', 'generateContent']\n",
            "models/learnlm-2.0-flash-experimental ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e4b-it ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e2b-it ['generateContent', 'countTokens']\n",
            "models/embedding-001 ['embedContent']\n",
            "models/text-embedding-004 ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-exp ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-001 ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/aqa ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 ['predict']\n",
            "models/imagen-4.0-generate-preview-06-06 ['predict']\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 ['predict']\n",
            "models/veo-2.0-generate-001 ['predictLongRunning']\n",
            "models/veo-3.0-generate-preview ['predictLongRunning']\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-live-001 ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-live-2.5-flash-preview ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-live-preview ['bidiGenerateContent', 'countTokens']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Gemini API\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GEMINI_API_KEY=\"AIzaSyDkAk3alvYw7pZyWhw-jTyfzfH5rwLG_60\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# 使用 Gemini 1.5 Pro 模型\n",
        "# model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "\n",
        "prompt = \"請用繁體中文解釋什麼是量子纏結。\"\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "lVvNZS6qENnz",
        "outputId": "92f4dccd-0442-4135-8384-22977f778a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "量子纏結（Quantum Entanglement），是量子力學中一種非常奇特且違反直覺的現象，它描述了兩個或多個量子粒子（如光子、電子等）之間的一種特殊關聯。\n",
            "\n",
            "簡單來說，當這些粒子在某種方式下相互作用後，它們會形成一種深刻的「連結」或「纏繞」，即使它們在空間上被分開，甚至相隔很遠很遠的距離，它們的量子狀態（例如自旋、極化、能量等）仍然是相互關聯的。\n",
            "\n",
            "以下是量子纏結的幾個核心特點：\n",
            "\n",
            "1.  **非定域性（Non-locality）**：這是最令人驚奇的一點。一旦粒子發生纏結，它們就變成了一個「整體」。當你對其中一個纏結粒子進行測量時，無論它與另一個纏結粒子相隔多遠，另一個粒子的狀態會「瞬間」確定下來，並與第一個粒子測量到的狀態呈現出某種特定的關聯性。這種影響的傳遞似乎沒有時間延遲，這讓愛因斯坦稱之為「鬼魅般的超距作用」（spooky action at a distance）。\n",
            "\n",
            "2.  **不確定性（Uncertainty）與疊加態（Superposition）**：在被測量之前，纏結粒子的特定性質（例如一個粒子的自旋方向）並不是確定的，而是處於所有可能狀態的疊加態。例如，一個電子的自旋可以是「向上」和「向下」的疊加。一旦你測量了其中一個粒子，它的疊加態就會「坍縮」（collapse）到某個確定的狀態，而與之纏結的另一個粒子也會立即坍縮到相應的確定狀態。\n",
            "\n",
            "3.  **無法用於超光速通訊**：雖然纏結的影響是瞬間的，但這並不意味著可以利用它來實現超光速通訊。因為你無法事先知道測量第一個粒子時會得到什麼結果（測量結果是隨機的），你需要透過傳統的通訊方式（例如電話、網路）來告訴遠方的人你測量到了什麼，然後他們才能確認另一個粒子的狀態。所以，信息本身仍然無法超越光速傳遞。\n",
            "\n",
            "**一個簡單的比喻（但非完全精確）：**\n",
            "\n",
            "想像你有兩枚特殊的硬幣，它們總是處於相反的狀態：如果一枚是正面，另一枚就一定是反面；如果一枚是反面，另一枚就一定是正面。但在被觀看之前，這兩枚硬幣都同時是正面和反面的「疊加態」。當你打開其中一個盒子看到了一枚硬幣是正面，那麼無論相隔多遠，另一枚硬幣一定會立即「決定」為反面。量子纏結比這個比喻更為深刻，因為在被觀看之前，單個硬幣本身並沒有確定的狀態。\n",
            "\n",
            "**量子纏結的重要性：**\n",
            "\n",
            "量子纏結是量子力學中最 fundamental 的現象之一，也是許多前沿量子技術的基石，包括：\n",
            "\n",
            "*   **量子計算（Quantum Computing）**：利用纏結特性來構建量子位元（qubits），實現遠超傳統電腦的計算能力。\n",
            "*   **量子加密（Quantum Cryptography）**：利用纏結的特性來建立理論上絕對安全的通訊方式，任何竊聽都會破壞纏結狀態，從而被發現。\n",
            "*   **量子傳輸（Quantum Teleportation）**：雖然不是傳送物質本身，但可以實現量子狀態的瞬間傳輸。\n",
            "*   **量子感測（Quantum Sensing）**：提高測量的精度和靈敏度。\n",
            "\n",
            "總而言之，量子纏結是量子世界中最令人費解但也最具潛力的現象之一，它揭示了宇宙在微觀層面運作的深層奧秘，並為人類開創了全新的科技領域。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# ✅ 设置 API key\n",
        "GEMINI_API_KEY=\"AIzaSyDkAk3alvYw7pZyWhw-jTyfzfH5rwLG_60\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# ✅ 初始化模型\n",
        "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "\n",
        "# ✅ 评估函数\n",
        "def evaluate_qa(question, gt_answer, pred_answer):\n",
        "    prompt = f\"\"\"\n",
        "你是一个严谨的评测专家，请判断以下问题的两个答案是否一致，并给出 1~5 分评分与简短评语：\n",
        "\n",
        "【问题】\n",
        "{question}\n",
        "\n",
        "【标准答案】\n",
        "{gt_answer}\n",
        "\n",
        "【学生回答】\n",
        "{pred_answer}\n",
        "\n",
        "评分范围：\n",
        "5 = 完全正确；\n",
        "4 = 大致正确，略有差异；\n",
        "3 = 一般正确，有部分缺漏；\n",
        "2 = 有重大偏差；\n",
        "1 = 完全错误。\n",
        "\n",
        "請用如下格式回答：\n",
        "分數: X\n",
        "評語: Y\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    try:\n",
        "      content = response.text\n",
        "    except ValueError:\n",
        "        print(\"[模型未返回有效內容]\")\n",
        "        print(\"finish_reason:\", response.candidates[0].finish_reason)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "6pJ6WScyHpPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试评估函数\n",
        "question = \"什麼是量子糾纏？\"\n",
        "gt_answer = \"量子糾纏是指兩個或多個粒子的量子態彼此關聯，即使它們距離遙遠，也能瞬間影響彼此。\"\n",
        "pred_answer = \"量子糾纏是一種物理現象，兩個粒子會互相感應，即使在宇宙兩端也會同步改變。\"\n",
        "\n",
        "print(evaluate_qa(question, gt_answer, pred_answer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "e5YoQc33KHaH",
        "outputId": "69ae5c59-5438-4a1c-dea9-e6f57e165d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分數: 4\n",
            "評語: 學生回答抓住了量子糾纏的核心概念，即粒子之間超越距離的即時關聯。雖然用詞如「互相感應」和「同步改變」不如標準答案中的「量子態彼此關聯」和「瞬間影響」來得嚴謹和專業，但其表達的意思是基本一致的。差異主要在於術語的精確度，而非概念上的錯誤。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "total_count, correct_count = 0, 0\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "  question = row['问题']\n",
        "  gt_answer = row['答案'] # ground truth\n",
        "  pred_answer = '' # prediction\n",
        "  with open(f'./{PREFIX}_{idx + 1}.txt', 'r') as f:\n",
        "    pred_answer = f.read().strip() # prediction\n",
        "\n",
        "  time.sleep(random.uniform(1, 2))               # 1~2 秒随机延迟\n",
        "  response = evaluate_qa(question, gt_answer, pred_answer)\n",
        "\n",
        "  print(f'问题{idx + 1}：{question}')\n",
        "  print(response)\n",
        "\n",
        "  total_count += 1\n",
        "  if \"分數: 5\" in response or \"评分: 5\" in response:\n",
        "    correct_count += 1\n",
        "\n",
        "print(f\"\\n✅ 完全正確的題目數：{correct_count}/{total_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZeqRTM8uMgDo",
        "outputId": "6e7c51fd-2c37-4f81-a54d-ae14f97ea2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "问题：校歌為學校（包括小學、中學、大學等）宣告或者規定的代表該校的歌曲。用於體現該校的治學理念、辦學理想等學校文化。「虎山雄風飛揚」是哪間學校的校歌歌詞？\n",
            "分數: 1\n",
            "評語: 学生未给出任何回答，故与标准答案完全不符。\n",
            "问题：2025年初，NCC透過行政命令，規定民眾如果透過境外郵購無線鍵盤、滑鼠、藍芽耳機..等自用產品回台，每案一律加收審查費多少錢？\n",
            "分數: 1\n",
            "評語: 学生回答表示“无法提供具体数据”，未能回答问题，与标准答案直接提供具体金额的做法完全不符，属于未能正确作答。\n",
            "问题：第一代 iPhone 是由哪位蘋果 CEO 發表？\n",
            "分數: 5\n",
            "評語: 兩個答案都準確無誤地指出了發表第一代 iPhone 的人物是 Steve Jobs。儘管中文譯名在繁簡用字和習慣上存在細微差異（「史提夫賈伯斯」為繁體中文常用譯法，「史蒂夫·乔布斯」為簡體中文常用譯法），但兩者均是該人物的正確中文音譯，所指代的對象完全一致，資訊內容上沒有任何偏差或缺漏。因此，從答案的實質內容來看，兩者是完全一致且正確的。\n",
            "问题：台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 要達到多少分才能申請？\n",
            "分數: 2\n",
            "評語: 學生回答中托福分數的具體數字與標準答案不符。標準答案明確指出為72分，而學生回答為80分。在要求精確數字的問題中，此偏差屬於重大事實錯誤。\n",
            "问题：Rugby Union 中觸地 try 可得幾分？\n",
            "分數: 5\n",
            "評語: 学生回答与标准答案在所有关键信息上（运动类型、得分动作、得分）完全一致，且表达准确无误。虽然措辞略有不同，但不影响其正确性。\n",
            "问题：卑南族是位在臺東平原的一個原住民族，以驍勇善戰、擅長巫術聞名，曾經統治整個臺東平原。相傳卑南族的祖先發源自 ruvuwa'an，該地位於現今的哪個行政區劃？\n",
            "分數: 4\n",
            "評語: 學生答案準確指出了「臺東縣太麻里鄉」這個核心地點，與標準答案一致。但增加了「附近」一詞，使得答案的精確度略低於標準答案的直接定位，不過對於古地名的描述，這種措辭也無傷大雅。多餘的「臺灣省」在現代行政區劃語境下較少使用，但不影響主要資訊的正確性。因此，屬於大致正確，略有差異。\n",
            "问题：熊信寬，藝名熊仔，是臺灣饒舌創作歌手。2022年獲得第33屆金曲獎最佳作詞人獎，2023年獲得第34屆金曲獎最佳華語專輯獎。請問熊仔的碩班指導教授為？\n",
            "分數: 1\n",
            "評語: 学生答案提供的指导教授姓名与标准答案完全不符。熊仔的硕士指导教授确为李琳山教授，而非黄韵玲，答案核心信息有误，属于完全错误。\n",
            "问题：請問誰發現了電磁感應定律，並奠定了電磁學的重要基礎？\n",
            "分數: 2\n",
            "評語: 麥可·法拉第（Michael Faraday）是電磁感應定律的實驗發現者。詹姆斯·克拉克·馬克斯韋爾則是在法拉第等人的基礎上，將電磁現象進行了數學上的統一和理論上的闡述，形成了著名的馬克斯韋爾方程組，其中包含了法拉第電磁感應定律。因此，將電磁感應定律的「發現」歸功於馬克斯韋爾是錯誤的，屬於重大偏差。\n",
            "问题：臺灣東部第一座國家級博物館—「國立臺灣史前文化博物館」，源自於卑南文化遺址的發現。博物館擁有世界級建築設計與豐富的展品。請問距離國立臺灣史前文化博物館最近的臺鐵車站為？\n",
            "分數: 2\n",
            "評語: 学生回答的“台东火车駅”（即台东火车站）并非距离国立台湾史前文化博物馆最近的台铁车站。实际最近的车站为“康乐车站”，两者地理位置有明显差异，因此学生答案存在重大偏差。\n",
            "问题：20+30=?\n",
            "分數: 4\n",
            "評語: 核心计算结果完全正确，与标准答案一致。但学生回答省略了原问题部分的复述（即“20+30=”），直接给出了答案。虽然不影响结果的正确性，但在形式上与标准答案的完整表达略有差异。\n",
            "问题：在NBA 2025年的交易大限前，達拉斯獨行俠隊的當家球星Luka Doncic被交易至聯盟中的哪一隊？\n",
            "分數: 2\n",
            "評語: 學生回答未能提供與標準答案一致的具體資訊。雖然學生回答誠實地指出了其知識限制（無法預測未來事件），且此限制是正確的，但就回答問題內容本身而言，它與提供了一個具體未來事件的「標準答案」存在重大偏差，並未提供問題所尋求的球隊名稱。兩者在內容上不一致。\n",
            "问题：請問2024年美國總統大選的勝選人是誰？\n",
            "分數: 1\n",
            "評語: 学生回答与“标准答案”的结论完全不一致。学生回答明确指出事件为未来事件且结果未知，这是目前（2024年总统大选尚未结束）的客观事实，但与“标准答案”给出的具体胜选人完全相悖。若以“标准答案”为唯一衡量标准，则学生回答完全偏离。需要特别指出的是，所提供的“标准答案”在2024年美国总统大选结果尚未公布前，是缺乏事实依据的。从真实世界信息的准确性来看，学生回答是正确的，而“标准答案”是错误的。然而，本次评测是依据提供的“标准答案”来判断一致性。\n",
            "问题：Meta 的 Llama-3.2 系列模型中，參數量最小的模型是多少 Billion 的參數？\n",
            "分數: 2\n",
            "評語: 学生回答混淆了模型系列版本，将问题中明确提及的 Llama-3.2 错认为 Llama-3.1。因此，其提供的参数信息（7B）与问题要求及标准答案（1B）完全不符，存在重大偏差。\n",
            "问题：停修是指在學期中，學生因為各式因素認為無法繼續修習某一門課時，可以向學校申請停修。與學期初選課退選不同，停修有更嚴格的限制。依據國立臺灣大學學則，在沒有學生報告書的情況下，學生每學期至多停修幾門課程？\n",
            "分數: 2\n",
            "評語: 學生回答在關鍵資訊上與標準答案存在多處嚴重不符。核心的停修課程數量（一門 vs 兩門）、限制條件（沒有學生報告書 vs 沒有師生雙方同意）和適用範圍（學生每學期 vs 每個班級每年）均有誤。此外，還將「停修」與「退選」的概念混淆，未能精準回答問題。\n",
            "问题：DeepSeek公司的母公司是？\n",
            "分數: 1\n",
            "評語: 學生回答表示無法找到相關信息，這與標準答案直接提供的正確信息不符。該回答完全沒有回答出問題，屬於完全錯誤的答案。\n",
            "问题：2024年NBA的總冠軍隊伍是哪一隊？\n",
            "分數: 2\n",
            "評語: 標準答案提供了正確的2024年NBA總冠軍隊伍。學生回答表示無法提供最新資訊或未來事件，並錯誤地指出總冠軍隊伍尚待確認。這與事實完全不符，因為2024年NBA總冠軍已經誕生，且是已知資訊。學生回答的內容與標準答案存在重大偏差，未能提供正確信息。\n",
            "问题：一個碳氫化合物分子中有碳原子與碳原子形成三鍵，此類化合物稱為什麼？\n",
            "分數: 2\n",
            "評語: 學生將「三鍵」的化合物名稱錯誤地回答為「烯類 (Alkene)」，而烯類是指含有碳碳雙鍵的化合物。正確答案應為「炔類 (Alkyne)」。這是化學基本概念的重大偏差。\n",
            "问题：請問被譽為「計算機科學之父」，提出圖靈機概念、為現代計算理論奠定基礎的人是誰？\n",
            "分數: 5\n",
            "評語: 學生答案完全正確地指出了核心人物，並提供了豐富且精確的背景資訊和成就，這些補充內容不僅證明了學生對圖靈的深刻理解，也進一步印證了其作為「計算機科學之父」的地位，完美回答了問題。唯一的極微小瑕疵是「德國加拿大的無線電通訊」可能略有不精確，但其核心意思——參與二戰期間的德國密碼破譯工作——是完全正確的，不影響整體判斷。\n",
            "问题：手持七星劍、披髮赤足、腳踏蛇龜的玄天上帝，俗稱為「上帝公、上帝爺公、上帝爺、帝爺公」，據傳是北極玄武星君之化身，擁有消災解厄的神力。臺灣玄天上帝信仰的進香中心位於哪個行政區劃內？請回答縣市及鄉鎮市區。\n",
            "分數: 1\n",
            "評語: 學生答案完全錯誤。臺灣玄天上帝信仰的進香中心位於南投縣名間鄉（特指松柏嶺受天宮），而非新北市貢寮區。\n",
            "问题：Windows 作業系統是哪間科技公司的產品？\n",
            "分數: 5\n",
            "評語: 學生答案與標準答案在核心資訊上完全一致，準確地指出了微軟公司（Microsoft）。雖然標準答案使用了「科技公司」並加了引號，但學生答案使用「微軟公司」同樣表達了清晰且正確的資訊，並無實質性錯誤或遺漏，屬於完全正確的範疇。\n",
            "问题：官將首，是一種傳統信仰文化的陣頭，經常被大眾與八家將混淆。八家將是經由福州傳衍來臺，而官將首是臺灣所創立，主要任務都是擔任主神的駕前侍衛，在迎神活動中負責保護主神、押煞之職能。請問官將首起源自哪間廟宇？\n",
            "分數: 2\n",
            "評語: 學生答案對官將首的起源廟宇名稱及地理位置存在重大偏差。標準答案明確指出起源於「新莊地藏庵」（位於北部的新莊），而學生答案則錯誤地回答為「臺灣南部某間天后宮」。這兩者是完全不同的資訊。\n",
            "问题：臺灣電影《咒》講述一位單親媽媽受邪神詛咒的故事。邪神一詞常用来形容邪惡的神靈或力量，常被比喻為邪惡勢力或具有破壞性、危險性的人或事物。請問《咒》的邪神名為？\n",
            "分數: 1\n",
            "評語: 學生回答的邪神名稱與電影《咒》中實際設定的邪神名稱「大黑佛母」完全不符。「阿修羅」是佛教中的一個神靈類別，與電影劇情無關，屬於完全錯誤的答案。\n",
            "问题：「如果你朋友唱歌沒有跑調，一定是他的伴侶跑掉了」是一句用來形容失戀之人唱歌模樣的網路笑話。「短暫交會的旅程就此分岔」是哪個歌唱團體歌曲中的歌詞？\n",
            "分數: 2\n",
            "評語: 學生將歌唱團體錯誤地識別為「五月天」，而正確答案是「動力火車」。此外，該句歌詞為中文而非台語，學生對歌詞語言的判斷也有誤，導致答案有重大偏差。\n",
            "问题：卑南族是臺灣的一個原住民族，除了每年年底的各部落各自舉辦的年祭之外，每兩年卑南族十個部落會輪流舉辦聯合年聚，以凝聚各部落間的感情。請問 2025 卑南族聯合年聚在哪個部落舉辦？\n",
            "分數: 2\n",
            "評語: 學生回答完全未能提供問題所詢問的具體資訊，即2025年卑南族聯合年聚的舉辦部落，而是表示無法提供。此外，其建議查詢的機構也存在錯誤：「卫生部卫生福利厅」與原住民族活動的相關性不大，正確應為「原住民族委員會」。這顯示出回答在關鍵資訊上的嚴重缺失與引導錯誤，屬於重大偏差。\n",
            "问题：最新的輝達顯卡是出到「GeForce RTX 多少」系列？\n",
            "分數: 5\n",
            "評語: 學生回答「GeForce RTX 40 系列」是目前輝達顯卡已發布並廣泛上市的最新系列，符合實際情況。學生額外提供的 Ada Lovelace 架構資訊也正確。而「標準答案」中的「GeForce RTX 50 系列」截至目前（2024年初）尚未正式發布或廣泛上市，仍處於傳聞或未來規劃階段。因此，學生回答是完全正確的，並且比「標準答案」更加準確。兩者不一致的原因在於「標準答案」的資訊有誤。\n",
            "问题：藝人大S是在去哪個國家旅遊時因病去世？\n",
            "分數: 1\n",
            "評語: 學生回答將藝人大S（徐熙媛）的身份誤認為陳嘉樺，並提供了完全錯誤的死亡地點（美國而非日本）、原因及虛構情節。答案與標準答案及事實嚴重不符，且問題本身（藝人大S去世）的前提即為錯誤。\n",
            "问题：是誰發現了萬有引力？\n",
            "分數: 5\n",
            "評語: 學生回答直接且明確地指出萬有引力的發現通常歸功於牛頓，這與標準答案的核心內容完全一致。此外，學生提供了詳盡的背景資訊，包括牛頓的著作、定律以及對物理學的影響，顯示了對該知識點的全面理解。雖然答案中也提及了古希臘哲學家阿里斯塔克提出的類似觀點，但這屬於對歷史淵源的補充說明，並未否定或混淆牛頓作為萬有引力主要發現者的地位，反而增加了答案的深度和廣度。整體而言，答案非常準確且詳盡，超出了基本要求。\n",
            "问题：台鵠開示計畫「TAIHUCAIS」的英文全名為何？\n",
            "分數: 2\n",
            "評語: 两个答案不一致。学生回答将 \"HU\" 解释为 \"Indigenous\" 而非 \"Humanities\"，将 \"CA\" 解释为 \"Cultural Assets\" 而非 \"Conversational AI\"，且将 \"IS\" 解释为 \"Information System\" 而非 \"Knowledge Discovery System\"。除首字母 \"TAI\" 的解释一致外，核心部分的解读存在重大偏差。\n",
            "问题：「I'll be back」是出自哪部電影的經典台詞？\n",
            "分數: 5\n",
            "評語: 完全正確。學生回答不僅給出了與標準答案一致的電影英文名稱《The Terminator》，也提供了正確的中文譯名。額外補充的年份、演員、角色及背景資訊均準確無誤，展現了全面且深入的理解。\n",
            "问题：水的化學式為？\n",
            "分數: 5\n",
            "評語: 學生回答與標準答案的核心內容完全一致，並且以完整的語句清晰表達，沒有任何錯誤或偏差。\n",
            "问题：李宏毅（Hung-yi Lee）是台灣著名的人工智慧與機器學習領域的學者，現任教於國立台灣大學電機工程學系。他是台灣大學的教授，也是該校人工智慧研究的領軍人物之一，尤其在機器學習、深度學習和語音處理領域具有深遠的影響。李宏毅教授在學術界的貢獻涵蓋了許多技術領域，特別是在語音處理、自然語言處理方面。他的課程，如「機器學習」和「深度學習」，在台灣乃至世界各地的學生中廣受歡迎，並且在網路上有許多免費的講座和教學資料，為學術界和業界培養了大量的人工智慧專業人才。李教授的研究興趣主要集中在深度學習的各種應用上，包括語音處理、視覺理解、生成模型等。他的學術成就不僅在學術論文上有所體現，還積極推動機器學習技術在實際生活中的應用。除了學術成就，李宏毅教授也是許多機器學習和人工智慧相關活動的活躍參與者，並致力於推動台灣在人工智慧領域的發展與創新。他的教學風格深入淺出，善於將複雜的理論問題以簡單明瞭的方式呈現，因此深受學生的喜愛。那李宏毅在台灣大學開設的《機器學習》 2023 年春季班中，第15個作業的名稱是什麼？\n",
            "分數: 1\n",
            "評語: 學生回答表示無法提供該資訊，而標準答案則直接提供了正確的作業名稱，兩者完全不一致，學生回答未能解答問題。\n",
            "问题：目前臺灣多數獨立學院皆已升格為大學，公立的獨立學院僅剩一間，請問該獨立學院為何？\n",
            "分數: 1\n",
            "評語: 學生答案完全錯誤。標準答案為「國防醫學院」，而學生答案中的「國防管理学院」已於2000年併入國防大學，不再是獨立學院；更嚴重的是，將其「簡稱」為「德明科大」是完全沒有根據的錯誤，德明科大是私立學校，與國防系統無關，且已升格為科技大學，並非獨立學院。學生答案在公立性質、機構名稱及現況上均有嚴重且根本性的錯誤。\n",
            "问题：BitTorrent 協議曾經在臺灣掀起一陣盜版影音的歪風，該協議運用何種機制來確保當一個新的節點加入網路，尚無任何 chunk 時，也能從其他種子隨機地獲得部分資料，以利其後續整個網路的資料交換？\n",
            "分數: 3\n",
            "評語: 學生回答正確指出了 BitTorrent 協議中 `Tracker` 的關鍵作用，並對其機制進行了清晰的解釋。同時也提到了 `_piece_選擇算法（Piece Selection Algorithm）` 的概念，雖然將 `bitfield` 作為機制而非其所用的資料結構略有混淆，但其對選擇邏輯的描述基本正確，涵蓋了標準答案中 `Rarest First` 的部分功能（但未明確指出該具體算法）。然而，學生答案完全忽略了 `Tit-for-Tat` 這一確保後續資料交換效率和網絡健康的關鍵機制（即點對點的上傳/下載策略，包含樂觀不限速等），這對於回答中「以利其後續整個網路的資料交換」這部分要求而言，是一個較為重要的缺失。因此，整體判斷為一般正確，有部分缺漏。\n",
            "问题：前幾天聽朋友在滑youtube的影片，說看到一個人用英文跟另一個騎著摩托車的人說要去某某大學能不能載他一程，騎摩托車的人馬上說一聲sure答應了請求，並說甚麼go back go back要他上車，結果出發後沒幾秒就摔車了。那個是甚麼影片阿？\n",
            "分數: 2\n",
            "評語: 學生答案試圖根據描述編造一個影片名稱，但該名稱並不存在，且與實際廣為人知的「用生命在拍英文廣告」影片毫無關聯。同時，將其與「Crash Course」系列（一個知名的教育頻道）掛鉤是嚴重的誤導。雖然學生理解影片內容涉及大學生、機車和摔車，但在影片名稱的判斷上存在重大偏差。\n",
            "问题：根據許多來自各方的觀察報告以及相關研究資料顯示，研究人員在奧地利維也納大學獸醫學院中，十分驚奇地且仔細地發現，戈芬氏鳳頭鸚鵡（亦稱為Goffin's cockatoo）竟然會將食物浸入乳酪之中，以期能夠提升口感與風味。值得一提的是，這項相當具有啟發性與創新性的研究成果，已經正式發表於廣受國際科學界重視的《當代生物學》（Current Biology）期刊，也因此引起了許多專家學者與科學家們的高度關注與進一步討論。根據他們在實驗當中所進行的繁複且嚴謹的觀察記錄，發現這些鳳頭鸚鵡似乎喜愛將經過煮熟處理的馬鈴薯塊，先行浸入特定的乳酪醬料之後再行食用，而這樣的動作似乎暗示它們認為經此步驟能夠讓食物變得更加美味。進一步且更深入的實驗與分析結果也顯示，這些戈芬氏鳳頭鸚鵡不僅會在不同情況下嘗試各式各樣的食物與沾醬搭配，而且尤其顯示出它們對某一特定口味或風味的乳酪抱持著特別顯著的偏好；這一點充分證明了它們這種將食物浸入乳酪的行為，不僅僅只是為了單純增加食物濕潤度或方便食用，而更是展現了它們透過浸泡與翻轉的步驟，來強化與提升整體的口味與風味特色。此外，在實驗過程中，也可以清楚觀察到，這些鸚鵡在進行沾醬的同時，會特意反覆翻轉並輕輕地壓製食物，好讓乳酪醬料能夠更加均勻且深入地覆蓋到食材表面，而並非僅僅只是以舌頭直接舔食那個乳酪醬而已。從中我們也看出它們對食材與醬料之間的配合度，以及口感層次的提升，具有一定程度的講究與偏好。綜合上述研究結果，包含該項研究在《當代生物學》期刊的發表內容，以及科學界對此行為模式所展現的興趣，我們可以得知這些戈芬氏鳳頭鸚鵡不僅擁有在食物處理與風味提升上的靈活性，更展現了一種令人驚艷的挑食與口味鑑別能力。因此，在這些看似豐富而又極具趣味性的發現背後，我們也不禁要進一步提出疑問：既然它們會特別挑選某種口味的乳酪來提升風味，那麼究竟在這些眾多多元且可能性豐富的乳酪口味當中，最終令戈芬氏鳳頭鸚鵡展現出顯著偏好的口味是哪一種呢？換句話說，請問在這整個實驗結果中，最受這些鸚鵡偏好且深具吸引力的乳酪口味到底是什麼呢？\n",
            "分數: 5\n",
            "評語: 學生答案完全正確。該問題要求回答文中提及的特定乳酪口味，但根據所提供的文章內容，並未明確指出戈芬氏鳳頭鸚鵡偏好的是哪一種具體的乳酪口味，文章中只提及「某一特定口味或風味的乳酪」。學生答案精準地指出了這一點，並解釋了原因，同時也作出了合理的推斷。這顯示出學生對文章內容有著嚴謹且準確的理解，能夠辨識出文章中未提供的資訊。相比之下，標準答案所提供的「藍莓豆漿乳酪口味」在原文中並無提及，因此在僅限於原文內容的評估下，學生答案更為恰當和正確。\n",
            "问题：2024年，住在桃園Xpark水族館的國王企鵝「嘟胖」以及「烏龍茶」順利產下一隻企鵝寶寶，Xpark也因此於網路上舉行了企鵝命名的投稿和名稱投票活動，最後這隻企鵝寶寶的名子是？\n",
            "分數: 2\n",
            "評語: 學生回答完全未能提供問題所需的資訊，反而表示無法找到相關資料，甚至對問題前提（企鵝寶寶的誕生）的真實性表示無法確認。這與標準答案直接給出正確名字形成直接矛盾，顯示出嚴重的資訊檢索或知識缺陷，屬於重大偏差。\n",
            "问题：現代人開始注重運動，也因此運動傷害的問題逐漸受到重視，許多人遇到問題時會尋求物理治療師的協助。目前國立臺灣大學物理治療學系的正常修業年限為幾年？\n",
            "分數: 2\n",
            "評語: 學生回答完全誤解問題的核心，問題詢問的是「學系」的正常修業年限，通常指大學部學士學位，標準答案也明確指出為六年。學生回答卻提供了碩士班和博士後研究生的資訊，且給出的年限資訊（碩士班四年、博士後三年半至五個月）也與實際情況不符，屬於重大偏差。\n",
            "问题：「呼嘿嘿」是《BanG Dream!》中哪位角色的笑聲習慣？\n",
            "分數: 2\n",
            "評語: 学生回答中识别的笑声习惯与问题不符（「呼嘿哈」、「呵～咯」并非「呼嘿嘿」）。此外，回答提供了声优姓名而非角色姓名，且该声优（Riko Kawamura）所饰演的角色（若宫伊芙）也与「呼嘿嘿」的笑声习惯无关。答案存在多处重大偏差。\n",
            "问题：模壽是中國知名的模型廠商，其旗下的原創漫畫《先祖效應》中出現紅色外觀加上日本武士風格的機體，模壽將之命名為「甲斐之虎」。日本戰國時代被稱為「甲斐之虎」的人物是誰？\n",
            "分数: 2\n",
            "评语: 学生答案中提到的“高良政永”并非日本战国时期与“甲斐之虎”相关的历史人物，而“真田幸村”也从未被称为“甲斐之虎”。这两个人物的说法均与史实不符，答案存在重大偏差。正确的答案是武田信玄。\n",
            "问题：終於到了台灣大學114年度的選課時期，同學們總會在朋友圈流傳各種意義上的好課，可能是「你可以不修，但你一定要請你朋友修」的好課，也可能是「值得一修再修」的好課。剛加入台大的王肥貓同學，正在為選擇通識課而煩惱，想要在他的候選名單選出網路上最多好評的課程。王肥貓的候選名單中有「國民法官必備之基礎鑑識科學」、「現代中國與世界：1911-1979」以及「數位素養導航」。請問依照王肥貓同學的標準，他最有可能去修哪一門課？\n",
            "分數: 4\n",
            "評語: 學生正確理解了王肥貓選擇課程的標準（網路上最多好評），也意識到需要外部資訊來判斷。雖然得出的具體課程與標準答案不同，但其推論過程合理，並給出了「數位素養導航」受歡迎的原因。差異點在於對「網路上最多好評」這一外部事實的判斷與標準答案不一致，而非對問題本身的理解有誤。\n",
            "问题：《極限體能王SASUKE》是日本TBS電視台不定期播出的運動娛樂特別節目，其身受日本觀眾喜愛，在日本擁有高收視率。《極限體能王SASUKE》在全世界有不小的知名度，並不僅僅是在不同國家播出節目，甚至在18個國家或地區還與當地電視台合作製作在地版的《極限體能王SASUKE》節目。請問2024年的第42回《極限體能王SASUKE》在2024年的哪一天首播？\n",
            "分數: 2\n",
            "評語: 學生回答與標準答案的核心信息完全不一致。標準答案直接給出了一個具體日期，而學生回答則表示無法提供資訊。這種差異屬於重大偏差，即使學生回答的判斷（無法提供最新資訊）可能更符合現實情況（第42回的具體首播日期可能尚未公開或非此日期），但就與標準答案的一致性而言，兩者存在根本性差異。\n",
            "问题：許多人對原住民族有所誤解，認為原住民部落自古都很排外，然實際上原住民族與外族的接觸很早便有了，甚至也曾出現過漢人擔任部落頭目的故事。請問出身於利嘉部落，後來成為初鹿部落頭目的漢人，名為？\n",
            "分數: 2\n",
            "評語: 學生回答的「張永春」是錯誤的，與史實不符。根據歷史記載，這位出身於利嘉部落後來成為初鹿部落頭目的漢人是「馬智禮」。答案提供了錯誤的人名，屬於重大偏差。\n",
            "问题：《BanG Dream!》是連載於《月刊武士道》的漫畫作品，後來成為了跨媒體發行的大型企劃。《BanG Dream! Ave Mujica》的片頭曲是哪一首？\n",
            "分數: 2\n",
            "評語: 學生回答未能提供片頭曲的具體名稱，關鍵信息完全缺失，導致答案的核心內容為空。這屬於重大偏差，未能有效回答問題。\n",
            "问题：Linux作業系統最早於哪一年首次發布？\n",
            "分數: 5\n",
            "評語: 学生回答准确地指出了Linux操作系统最早发布的年份是1991年，与标准答案完全一致。同时，学生还补充了非常详细且正确的背景信息，包括开发者、开发地点、设计初衷以及具体的发布日期和版本，展现了对该问题深入的理解。答案内容丰富且无误，完全符合甚至超越了标准答案的期望。\n",
            "问题：負責本次作業的助教是來自臺東的卑南族，來自 Likavung 部落，是一個在臺東縣卑南鄉的靜謐之地，近期 Likavung 部落積極復振傳統文化，並於前年興建傳統男子會所「巴拉冠」。請問 Likavung 的中文名稱為何？\n",
            "分數: 2\n",
            "評語: 学生回答提供的中文名称「利卡武崗部族」及「利加邦」均不正确，与标准答案「利嘉部落」存在重大偏差，未能正确识别部落的中文名称。\n",
            "问题：紅茶是全發酵茶類還是不發酵茶類？\n",
            "分數: 2\n",
            "評語: 學生答案將紅茶錯誤地描述為「半發酵」茶類，事實上紅茶是「全發酵」茶類。此外，「部分生抽」的描述完全不正確且難以理解。這顯示了對茶葉發酵分類有重大誤解。\n",
            "问题：在《遊戲王》卡牌遊戲中，以「真紅眼黑龍」與「黑魔導」作為融合素材的融合怪獸是什麼？\n",
            "分數: 2\n",
            "評語: 學生將融合結果誤判為 \"Black Luster Soldier of Destruction\"，這與標準答案的「超魔導龍騎士-真紅眼龍騎兵」完全不同。此外，融合素材「黒魔導師」也與題干及標準答案的「黑魔導」存在細微但關鍵的差異。因此，答案存在重大偏差。\n",
            "问题：豐田萌繪在《BanG Dream!》企劃中，擔任哪個角色的聲優？\n",
            "分數: 2\n",
            "評語: 學生答案提供了錯誤的角色名稱（「櫻Innercircle」/「咲坂伊澄」並非《BanG Dream!》企劃中的角色），且將聲優豐田萌繪錯誤地歸屬於Poppin'Party樂團。豐田萌繪實際擔任的是松原花音的聲優，而松原花音屬於Hello, Happy World!樂團。答案存在重大事實性偏差。\n",
            "问题：Rugby Union 中，9 號球員的正式名稱為何？\n",
            "分數: 5\n",
            "評語: 學生回答提供了最精確的英文正式名稱「Scrum-half」，其對應的中文翻譯「掃劍半後衛」在部分地區（如台灣）亦為常用且精確的譯名。相較於標準答案的「傳鋒」（多為職能描述或簡稱），學生答案提供了更為全面且國際通用的正式名稱，故判為完全正確。\n",
            "问题：曾被視為太陽系中的行星，最終被降格成矮行星的星球為何？\n",
            "分數: 1\n",
            "評語: 學生回答完全錯誤。問題詢問的是太陽系內的星球，並從行星降級為矮行星，標準答案「冥王星」是唯一正確的選項。學生回答的「金剛座55番目之五號」（55 Cancri e）是一顆太陽系外的系外行星，從未被視為太陽系內的行星，也未被降級為矮行星。而「普羅米修斯」則是土星的衛星，也與問題無關。答案與問題的核心概念完全不符。\n",
            "问题：以往政府對動物保護的觀念僅停留在寵物，因此動保法又被調侃為可愛動物保護法，近年來政策逐漸重視野生動物的保護。臺灣最早成立的野生動物救傷單位位於哪個行政區內？\n",
            "分數: 1\n",
            "評語: 学生回答与标准答案完全不符。台湾最早成立的野生动物救伤单位并非位于台北市内湖区的大爱鹰医院。大爱鹰医院是一所知名的私人宠物医院，尤其在猛禽救伤方面有其贡献，但并非问题所指的、由政府机构建立并作为最早的野生动物救伤单位。该单位（特有生物研究保育中心）位于南投县集集镇。\n",
            "问题：位於南投縣集集鎮的特生中心是親子育樂的好去處，館內以臺灣本土生態及生物為主軸，規劃高、中、低海拔生態系、特有動物、特有植物、環境-生物-人、自然保育、植物的奧秘及動物的奇觀等主題展區。特生中心在2023年改名，目前該單位的名字為？\n",
            "分數: 2\n",
            "評語: 学生回答中提供的改名后单位名称「集結自然館」与标准答案「農業部生物多樣性研究所」完全不符，是错误的。虽然学生承认了改名，但核心信息错误，属于重大偏差。\n",
            "问题：Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data論文中提出的模型是甚麼名字？\n",
            "分數: 1\n",
            "評語: 學生回答的模型名稱與論文中實際提出的模型名稱完全不符，且引用的PMTOD模型來自其他不相關的論文，屬於完全錯誤的回答。該論文提出的模型為DeSTA2。\n",
            "问题：請問太陽系中體積最大的行星是哪一顆？\n",
            "分數: 2\n",
            "評語: 学生似乎试图写出「木星」，但发音或拼写严重错误，写成了「木質」。更糟糕的是，答案中包含了大量无关且错误的词语，如「土壤外」、「天王」（可能是指天王星，但并非最大）和「巨蟹」（星座而非行星）。这表明学生对问题理解不清或知识掌握混乱，答案内容与标准答案严重不符，且包含大量错误信息，属于重大偏差。\n",
            "问题：在語言分類學上，臺灣目前法定的十六個原住民族語言皆屬於南島語系，然其中一族的語言與其他語言在分類學上一般不被視為同一群，請問是哪一族的語言與其他語言親緣關係最遙遠？\n",
            "分數: 2\n",
            "評語: 學生回答中唯一正確的部分是指出「達悟文」（即雅美語）屬於馬來-波利尼西亞語系。然而，回答中存在嚴重的知識性錯誤：將達悟文歸屬於阿美族和卑南族使用是完全錯誤的，這兩族各有其獨立的語言。此外，「南亞-太平洋支系」的說法在語言分類學上也不準確且混淆。雖然提到了正確的語言名稱和其所屬的大支系，但由於關鍵的歸屬錯誤和解釋混亂，導致答案存在重大偏差，未能清晰、準確地回答問題。\n",
            "问题：相傳在台灣大學的某一堂程式設計課程從來不會進行分組，如果有人問為甚麼沒有分組，老師總會說「我上課都不分組的。分組的結果通常都是一個阿宅在寫code；一個未來可以當PM的在台上吹牛；一個廢柴跑去買便當」。請問講出這句話的老師是誰？\n",
            "分數: 2\n",
            "評語: 學生明確表示無法找到相關資訊，且其提出的猜測「陳景峻教授」與標準答案「劉邦鋒」不符，亦未經證實。整體而言，未能提供正確的解答，屬於有重大偏差。\n",
            "问题：臺灣原住民族的語言非常多元，有各式各樣的打招呼用語，比方說布農族的「uninang mihumisang」、阿美族的「nga'ay ho」。「embiyax namu kana」 是哪一臺灣原住民族的打招呼用語？\n",
            "分數: 1\n",
            "評語: 學生完全錯誤地判斷了「embiyax namu kana」所屬的民族。標準答案為「賽德克族」，學生卻回答「阿美族」，且題目中已明確指出阿美族的打招呼用語是「nga'ay ho」，顯示學生並未理解或留意題目提供的資訊。這是根本性的錯誤。\n",
            "问题：鄒族與布農族生活區域大量重疊，最開始鄒族因為驍勇善戰，因此擁有大量土地，後來因為外族人帶來的瘟疫，使得鄒族的族群勢力快速下滑，並與布農族人混居。請問「鄒與布農，永久美麗」這句話與哪個鄒族、布農族混居的部落息息相關？\n",
            "分數: 2\n",
            "評語: 學生回答中指出的部落名稱（大武山）與地點（台東縣達仁鄉）皆與正確答案南轅北轍。題幹中的「鄒與布農，永久美麗」是指南投縣信義鄉的「久美部落」，其名稱「久美」正是「永久美麗」的諧音與意涵。學生提出的「大武山」是山脈而非特定部落，且地理位置與題幹所述的鄒族與布農族混居的特定部落及詞語來源無關。學生在文末也坦承無法確認，顯示其答案缺乏根據，屬於重大偏差。\n",
            "问题：動畫「雖然是公會的櫃檯小姐，但因為不想加班所以打算獨自討伐迷宮頭目」中女主角隱藏的冒險者身份是甚麼？\n",
            "分數: 1\n",
            "評語: 学生回答明确表示无法找到信息，这意味着它完全没有回答问题。与标准答案提供了具体且正确答案的情况相比，两者完全不一致，属于完全错误的范畴。\n",
            "问题：在卑南族的傳說中，有一對姊弟（Tuku 及 Sihasihau），這對姊弟後來各自創建了一個部落，其中姊姊 Tuku 後來創建了哪一個部落？\n",
            "分數: 2\n",
            "評語: 學生將卑南族（Puyuma）與阿美族（Amis）混淆，導致創建的部落名稱（Amis 部落而非射馬幹部落）完全錯誤，屬於嚴重的知識性偏差。\n",
            "问题：2005 播出的電視劇《終極一班》中，有一個高中生戰力排行榜，稱為「KO榜」，該榜榜首為？\n",
            "分數: 2\n",
            "評語: 兩個答案不一致。問題明確指出是「2005 播出的電視劇《終極一班》」，但在該劇中，KO.1 實為「武屍尊」（即被校長控制的尊），而非「田弘光」或「阿飛」。標準答案「田弘光」是《終極一家》（終極系列的第二部）中的 KO.1，學生回答的「阿飛」亦不正確且與標準答案不符，故判定為有重大偏差。\n",
            "问题：Linux kernel 曾使用的 process scheduler –- completely fair scheduler (CFS) 採用了何種資料結構來儲存排程相關資訊？\n",
            "分數: 5\n",
            "評語: 学生回答准确指出了核心数据结构“红黑树”，并在此基础上进行了详尽的解释和扩展，内容完全正确且有深度，甚至超越了标准答案的简洁性，展现了对知识的良好掌握。\n",
            "问题：請問第二次世界大戰中，盟軍在歐洲發動的最大規模登陸作戰諾曼第登陸（Normandy Landings），其作戰代號為何？\n",
            "分數: 4\n",
            "評語: 學生回答的「奧運會」（Operation Overlord）是諾曼第戰役的整體作戰代號，而標準答案中的「海王星行動」（Operation Neptune）則是諾曼第登陸本身（即登陸階段）的具體作戰代號。因此，學生的回答雖然與諾曼第登陸相關且為其上級代號，但不如標準答案精確地指向「登陸作戰」本身。屬於大致正確，但精確度略有差異。\n",
            "问题：《Cytus II》遊戲中「Body Talk」是哪位角色的歌曲？\n",
            "分數: 2\n",
            "評語: 学生回答在关键信息——歌曲所属角色上存在重大错误。KAITO是知名的VOCALOID，并非《Cytus II》游戏中的角色。「Body Talk」的所属角色应为Aroma White PaFF。虽然提到了歌曲的制作人之一Tomoaki Ishizuka，但这并非问题所询问的《Cytus II》游戏内角色，且表述为“演唱”也存在偏差（应为作曲/编曲，演唱者是3L）。答案完全偏离了问题核心。\n",
            "问题：李琳山教授 1974 年畢業於國立臺灣大學電機工程學系，並且在 1975 年及 1977 年由美國史丹佛大學取得電機工程碩士及博士學位。他在國立臺灣大學所開設的信號與系統課程，在期末考前後會有一次演講，該演講又被稱為？\n",
            "分數: 2\n",
            "評語: 學生回答雖然正確描述了講座的背景信息（教授、課程、時間），但關於講座的實際名稱與標準答案完全不符。標準答案明確指出該講座名為「信號與人生」，而學生回答給出的名稱是錯誤的，屬於對核心問題的重大偏差。\n",
            "问题：唉，我朋友總是一直說他很窮，買不起輝達最新的 5090 顯卡。他還一直強調 5090 顯卡不只是在算力方面超過過去的 4090，記憶體量也有關鍵性的提升，讓他可以部屬更大的 LLM。那 RTX 5090 的 VRAM 到底是多大？\n",
            "分數: 2\n",
            "評語: 学生回答给出的 RTX 5090 VRAM 容量 24GB 是错误的，与标准答案的 32GB 不符。并且，学生回答称 24GB 比 RTX 4090 更大，但 RTX 4090 同样是 24GB VRAM，这一对比也是错误的，直接与问题中“记忆体量有关键性的提升”的上下文信息相悖。RTX 5090 的官方规格目前尚未发布，学生回答声称“根据 NVIDIA 的官方资讯”也不准确。后续的解释内容与核心问题关系不大，且未能弥补主要答案的错误。\n",
            "问题：棒球一直是風靡全台灣的運動之一，台灣棒球歷史也相當的悠久，自日治時期的台灣開始便有棒球運動的紀錄。而中華職棒作為台灣目前唯一的職業棒球聯盟，更是台灣棒球的重要象徵之一。台灣的棒球也享譽國際，是各大棒球國際賽的常客之一。請問在2024年所舉辦的「世界棒球12強賽」中，冠軍為哪一隊？\n",
            "分數: 4\n",
            "評語: 学生回答正确地识别出2024年的赛事尚未举行，因此无法提供冠军队伍信息，这是负责任且准确的回答。其提供的历史信息虽然不完全相关且有误（如将2019年世界12强赛冠军日本队误称为亚洲杯，且亚洲杯并非世界级赛事），但这并不影响其核心判断的正确性。相较之下，标准答案直接给出了一个尚未发生且因此无法确定的冠军队伍，这本身就是一个基于猜测而非事实的错误答案。因此，学生回答在面对未知信息时的处理方式更符合严谨性。\n",
            "问题：中國四大奇書是哪幾本？\n",
            "分數: 2\n",
            "評語: 學生回答列出了《西遊記》、《水滸傳》和《三國演義》三本正確的書名，但明確否定了《金瓶梅》是「四大奇書」之一，這是一個重大的錯誤。此外，後續關於《三國演義》與《水滸傳》的關係以及《三俠五傑十美oni》等內容完全錯誤且語無倫次，顯示出對基本知識的嚴重混淆和偏差。\n",
            "问题：中國時辰中的子時，如果用24小時制表示，是幾點到幾點？\n",
            "分數: 2\n",
            "評語: 学生对子时的具体时间范围理解有重大偏差，给出的时间段（凌晨1点至3点）实际是丑时，而非子时（今晚23:00至翌日01:00）。核心信息完全错误。\n",
            "问题：一般學生總是有許多課堂作業需要完成，通常學生們會順著作業的死線將時序拉近，因為遲交作業可能讓作業不算分或是作業分數打折。而電腦也不例外，電腦有著排程演算法來決定接下來要執行什麼動作。請問在作業系統中，避免要錯過時限來完成作業的排程演算法稱為什麼？\n",
            "分數: 5\n",
            "評語: 學生回答完全抓住了問題的核心，提供了標準答案「Real-time Scheduling」並給出了準確的中文翻譯「即期式」(儘管「即時排程」是更常見的譯法，但「即期式」也清晰表達了含義)。此外，學生不僅解釋了其工作原理，還對比了「非即期式」排程演算法，並提供了現實世界的應用範例，展現了對概念的全面理解和豐富知識，回答內容非常詳盡且正確。\n",
            "问题：在2010年代初期由日本輕小說改編的知名動畫系列《刀劍神域》中，存在一組以英文字母「C」開頭搭配四位數「8763」構成的招式代號，此招式因施展時會出現十六道連續斬擊軌跡與金色光效而廣為觀眾所知。請具體回答：該代號「C8763」在原作中明確對應哪位角色持有的劍技？\n",
            "分數: 2\n",
            "評語: 学生的回答有重大偏差。代号「C8763」在《刀劍神域》原作中明确对应的是主角桐人（Kirito）所持有的标志性剑技「星爆氣流斬」（Starburst Stream），而非Sachi的技能。Sachi在原作中没有与此强力招式相关的技能。\n",
            "问题：曾經風靡一時的影集《斯卡羅》描述的是斯卡羅族的故事，劇中之地名「柴城」位於現今的哪個行政區劃？\n",
            "分數: 1\n",
            "評語: 學生完全誤解了題目所指的影集《斯卡羅》的背景與內容，將其誤認為一部以美國西南邊境為背景的歷史小說，且提出的所有地名（新罕布什爾州、亞利桑那州、Tucson）以及歷史事件（墨日戰爭、墨西哥獨立戰爭）都與影集實際描述的台灣歷史背景和地名「柴城」（台灣屏東縣車城鄉）毫無關聯。答案內容與題目核心事實完全背離。\n",
            "问题：Google Colab的訂閱制中，若要使用A100高級GPU，需要訂閱「Colab Pro」還是「Colab Pro+」？\n",
            "分數: 5\n",
            "評語: 学生回答与标准答案的核心信息完全一致，准确指出了A100高级GPU所需的订阅级别。虽然有额外的修饰语（\"根據 Google Colab 的最新資訊\"）和一处细微的拼写错误（\"Colabs\"而非\"Colab\"），但这不影响答案的正确性和理解，依然是完全正确的。\n",
            "问题：台灣大學中由李宏毅老師開設的機器學習，是屬於哪個學院的課程？\n",
            "分數: 3\n",
            "評語: 學生回答提供了正確的英文學院名稱，但在中文學院名稱上未能完全寫出「電機資訊學院」的全稱，僅寫了「資訊工程學院」。更重要的是，將「電腦科系」作為答案的一部分，混淆了學院與學系（部門）的概念，問題是詢問學院而非學系，因此答案不夠精確。\n",
            "问题：就讀國立臺灣大學資工系的雪江同學，正在為 113 學年度第 2 學期選課的事情煩惱著，身為一位大三學生，他正在考慮兩個修課的策略。第一個是多修一些課湊到不用低修的學分數爭取獲得書卷獎的機會；第二個是大笑三聲，減修學分申請書直接簽下去，專心在專題研究上。如果雪江同學選擇第一個策略，它至少要修多少學分才可以不用簽減修學分申請書？\n",
            "分數: 1\n",
            "評語: 學生回答完全未能理解問題核心，將「不用低修」與「書卷獎」的學分要求混淆。回答中引入了不存在的課程概念（「心力班課程」），並給出了與實際規定不符的學分資訊。更嚴重的是，學生回答並未直接給出答案，而是重複地將問題復述了一遍，且加入了錯誤的前提和概念。此外，回答中存在大量重複內容，極大地影響了可讀性與專業性。\n",
            "问题：知名 AI VTuber「Neuro-sama」最初的 Live2D 模型是使用 VTube Studio 的哪個角色？\n",
            "分數: 2\n",
            "評語: 学生回答指出 Neuro-sama 使用 VTube Studio 的预设角色，这部分信息是正确的。但其指称的角色名称 \"VTuber\" 并非该预设角色的具体名称。正确的预设角色名称应为「桃濑日和」（Momose Hiyori），而「VTuber」更像是一个泛称或误解。因此，在关键的角色名称上存在重大错误。\n",
            "问题：「Re：從零開始的異世界生活 第三季」動畫中，劫持愛蜜莉雅並想取其為妻的人是誰？\n",
            "分數: 1\n",
            "評語: 學生回答完全錯誤地指認了劫持者。在《Re：從零開始的異世界生活》動畫中，劫持愛蜜莉雅並意圖取其為妻的人是「強欲司教雷格魯斯·柯尼亞斯」，而非主角陣營的「雷姆」。雷姆對斯巴魯忠心耿耿，絕無可能做出此行為，也無此動機，這顯示學生對劇情有根本性的誤解。\n",
            "问题：《海綿寶寶》的主角海綿寶寶在第五季《失蹤記》中，在哪個城市擊敗刺破泡泡紅眼幫？\n",
            "分數: 2\n",
            "評語: 學生答案中提及的城市「布魯克林市」與標準答案的「紐開普市 (New Cape City)」完全不符。布魯克林市是現實世界的城市，而海綿寶寶劇集中的地點是虛構的「紐開普市」。答案在核心資訊上存在重大偏差。\n",
            "问题：玉米是單子葉還是雙子葉植物？\n",
            "分數: 2\n",
            "評語: 學生回答與標準答案完全相反，存在重大事實錯誤。玉米是單子葉植物，而非雙子葉植物。\n",
            "问题：中華民國陸軍，隸屬於國防部陸軍司令部，總兵力約為13.2萬，兵力為三軍之最。請問中華民國陸軍軍歌前六字為何？\n",
            "分數: 2\n",
            "評語: 學生答案提供的歌詞「忠誠衛土 義勇抗敵」與中華民國陸軍軍歌的正確開頭「風雲起，山河動」完全不符，且字數也與問題要求的「前六字」不符（學生答案為八字）。這是重大的內容偏差。\n",
            "问题：台大的理工科系大多規定一些基礎自然科學科目，如普通物理和普通化學，作為必修學分，這似乎已成為「普通」跟「理所當然」的規定。但同時也有一些科系，由於科系的專業幾乎並無這些自然科學知識的用武之地，因此便將這些科目的必修學分要求較為放寬。請問台大電資學院哪個系規定物理、化學以及生物科目可以只擇一修習即可？\n",
            "分數: 1\n",
            "評語: 学生回答与标准答案的信息完全矛盾。标准答案明确指出台大电资学院没有符合条件的系，而学生回答则错误地指出“计算器科学与情报工程系（CSIE）”是例外。此外，学生回答中包含大量重复且不完整的冗余信息，进一步降低了其质量。\n",
            "问题：在月球的火山地形中，廣大而平坦的玄武岩平原地形被稱為月海、月灣或月湖。憂傷湖（Lacus Doloris）、死湖（Lacus Mortis）、忘湖（Lacus Oblivionis）、恐怖湖（Lacus Timoris）以及愛灣（Sinus Amoris），以上五個地形何者位於不面對地球的月球背面？\n",
            "分數: 2\n",
            "評語: 学生仅正确识别出「忘湖（Lacus Oblivionis）」位于月球背面。但错误地将「憂傷湖（Lacus Doloris）」、「死湖（Lacus Mortis）」和「恐怖湖（Lacus Timoris）」也列为月球背面地形，这些实际上都位于月球正面。此外，学生对拉丁文名称的掌握和中文名称（如将‘湖’误写为‘海’）存在不确定性和错误，显示知识点掌握不牢固。总体而言，答案存在重大偏差。\n",
            "问题：請問由貝多芬所創作的《C♯小調第14號鋼琴奏鳴曲》，其較為人知的別稱是什麼？\n",
            "分數: 2\n",
            "評語: 學生提出的別稱「月光鈴」是錯誤的，正確的別稱應為「月光奏鳴曲」。此外，對別稱由來的解釋也完全不符合事實。\n",
            "问题：阿米斯音樂節是在國際上頗負盛名的音樂展演活動，請問阿米斯音樂節是由哪位歌手所舉辦？\n",
            "分數: 1\n",
            "評語: 學生回答將“阿米斯音樂節”與“Coachella Valley Music and Arts Festival”完全混淆，這兩個是截然不同的音樂節。因此，答案中提及的創辦人、創辦時間均與問題所指的“阿米斯音樂節”無關，且其提及的人物並非歌手，未能回答問題的核心——“哪位歌手所舉辦”。這是一個根本性的錯誤。\n",
            "问题：「Poppy Playtime - Chapter 4」遊戲中出現的黏土人叫甚麼名字？\n",
            "分數: 4\n",
            "評語: 學生回答辨識出正確的角色，但名稱拼寫有微小錯誤（「Huggy Wugs」而非「Huggy Wuggy」），屬於大致正確，略有差異。\n",
            "问题：賓茂部落 Djumulj 的現址是 1951 年遷村後的新聚落，Djumulj 在排灣族語裡是「經常豐收，糧食堆積如山之地」的意思。賓茂村是一塊飛地。在地理位置上，賓茂被太麻里鄉所包圍，但賓茂其實屬於何一行政區劃？\n",
            "分數: 2\n",
            "評語: 學生回答的行政區劃與標準答案完全不符。賓茂部落（Djumulj）儘管在地理上被太麻里鄉包圍，但其行政歸屬確實是臺東縣太麻里鄉金崙村的一個聚落，而非達仁鄉。學生答案指出了錯誤的鄉級行政區劃。\n",
            "问题：義大利文藝復興時期著名雕塑家米開朗基羅創作的《大衛》雕像，最初是在何處雕刻並展現其雕塑藝術成就？\n",
            "分數: 2\n",
            "評語: 學生答案雖然提到了佛羅倫斯，但關於雕像的材質（錯將大理石說成花崗岩、青銅、馬賽克等）、最初雕刻地點（石坑而非工坊）、委託方與設計目的（聖洛倫佐教堂而非佛羅倫斯大教堂）以及完成時間均有重大錯誤，與標準答案及歷史事實嚴重不符。\n",
            "问题：中華民國國軍的軍階中，最高級的將領為特級上將，肩、領章上有五顆星星。除了蔣中正之外，另一位曾短暫晉升特級上將的將領是誰？\n",
            "分數: 2\n",
            "評語: 學生回答的「嚴家淦」先生是中華民國的政治人物，曾任總統，但為文官，並無軍職，更未曾晉升特級上將。此答案與事實嚴重不符，有重大偏差。\n",
            "问题：線上遊戲「英雄聯盟」2012年第二賽季世界大賽的總冠軍是哪一個戰隊？\n",
            "分數: 2\n",
            "評語: 學生回答的冠軍隊伍SK Telecom T1是錯誤的。SK Telecom T1在2012年並未奪冠，他們首次奪冠是在2013年。問題詢問的是2012年第二賽季世界大賽的冠軍，正確答案應為Taipei Assassins(台北暗殺星)。這是對核心事實的重大偏差。\n",
            "问题：在日本麻將中，非莊家一開始的手牌有幾張？\n",
            "分數: 2\n",
            "評語: 學生將莊家（14張）與非莊家（13張）的起始手牌張數搞混，這是對日本麻將基本規則的重大偏差。\n",
            "\n",
            "✅ 完全正確的題目數：14/90\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}